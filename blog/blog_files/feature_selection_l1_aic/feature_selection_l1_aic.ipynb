{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load in the Auto MPG dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.3-py3-none-any.whl (7.0 kB)\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/Users/dylanskinner/opt/anaconda3/envs/acme1/lib/python3.7/site-packages/numpy-1.21.6.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name     role         type demographic description units  \\\n",
      "0  displacement  Feature   Continuous        None        None  None   \n",
      "1           mpg   Target   Continuous        None        None  None   \n",
      "2     cylinders  Feature      Integer        None        None  None   \n",
      "3    horsepower  Feature   Continuous        None        None  None   \n",
      "4        weight  Feature   Continuous        None        None  None   \n",
      "5  acceleration  Feature   Continuous        None        None  None   \n",
      "6    model_year  Feature      Integer        None        None  None   \n",
      "7        origin  Feature      Integer        None        None  None   \n",
      "8      car_name       ID  Categorical        None        None  None   \n",
      "\n",
      "  missing_values  \n",
      "0             no  \n",
      "1             no  \n",
      "2             no  \n",
      "3            yes  \n",
      "4             no  \n",
      "5             no  \n",
      "6             no  \n",
      "7             no  \n",
      "8             no  \n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "auto_mpg = fetch_ucirepo(id=9) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = auto_mpg.data.features \n",
    "y = auto_mpg.data.targets \n",
    "  \n",
    "# variable information \n",
    "print(auto_mpg.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Brief Feature Engineering</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylanskinner/opt/anaconda3/envs/acme1/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Change the values of the origin column to represent the country of origin as strings: 'US', 'Europe', and 'Asia'\n",
    "X['origin'] = X['origin'].replace({1: 'US', 2: 'Europe', 3: 'Asia'})\n",
    "\n",
    "# One-hot encode the origin column\n",
    "X = pd.get_dummies(X, columns=['origin'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# See how many NaN's are present in the horsepower column.\n",
    "print(X.horsepower.isna().sum())\n",
    "\n",
    "# Get the indices of the rows containing NaN's\n",
    "nan_indices = X[X.horsepower.isna()].index\n",
    "\n",
    "# Since there are only 6 NaN's, we can drop them from the dataset (also dropping the corresponding rows from y)\n",
    "X = X.dropna()\n",
    "y = y.drop(nan_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant column to the dataframe.\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stepwise Feature Removal</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.824\n",
      "Model:                            OLS   Adj. R-squared:                  0.821\n",
      "Method:                 Least Squares   F-statistic:                     224.5\n",
      "Date:                Wed, 03 Jan 2024   Prob (F-statistic):          1.79e-139\n",
      "Time:                        09:43:04   Log-Likelihood:                -1020.5\n",
      "No. Observations:                 392   AIC:                             2059.\n",
      "Df Residuals:                     383   BIC:                             2095.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const           -15.1014      4.681     -3.226      0.001     -24.305      -5.898\n",
      "displacement      0.0240      0.008      3.133      0.002       0.009       0.039\n",
      "cylinders        -0.4897      0.321     -1.524      0.128      -1.121       0.142\n",
      "horsepower       -0.0182      0.014     -1.326      0.185      -0.045       0.009\n",
      "weight           -0.0067      0.001    -10.243      0.000      -0.008      -0.005\n",
      "acceleration      0.0791      0.098      0.805      0.421      -0.114       0.272\n",
      "model_year        0.7770      0.052     15.005      0.000       0.675       0.879\n",
      "origin_Europe    -0.2232      0.566     -0.394      0.694      -1.336       0.890\n",
      "origin_US        -2.8532      0.553     -5.162      0.000      -3.940      -1.766\n",
      "==============================================================================\n",
      "Omnibus:                       23.395   Durbin-Watson:                   1.291\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.452\n",
      "Skew:                           0.444   Prob(JB):                     3.30e-08\n",
      "Kurtosis:                       4.150   Cond. No.                     8.71e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.71e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.824\n",
      "Model:                            OLS   Adj. R-squared:                  0.821\n",
      "Method:                 Least Squares   F-statistic:                     257.1\n",
      "Date:                Wed, 03 Jan 2024   Prob (F-statistic):          1.16e-140\n",
      "Time:                        10:00:11   Log-Likelihood:                -1020.5\n",
      "No. Observations:                 392   AIC:                             2057.\n",
      "Df Residuals:                     384   BIC:                             2089.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const          -15.4664      4.583     -3.375      0.001     -24.478      -6.455\n",
      "displacement     0.0241      0.008      3.155      0.002       0.009       0.039\n",
      "cylinders       -0.4831      0.320     -1.508      0.132      -1.113       0.147\n",
      "horsepower      -0.0177      0.014     -1.300      0.194      -0.045       0.009\n",
      "weight          -0.0068      0.001    -10.486      0.000      -0.008      -0.005\n",
      "acceleration     0.0791      0.098      0.806      0.421      -0.114       0.272\n",
      "model_year       0.7808      0.051     15.365      0.000       0.681       0.881\n",
      "origin_US       -2.7469      0.482     -5.699      0.000      -3.695      -1.799\n",
      "==============================================================================\n",
      "Omnibus:                       22.551   Durbin-Watson:                   1.286\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.755\n",
      "Skew:                           0.435   Prob(JB):                     7.72e-08\n",
      "Kurtosis:                       4.117   Cond. No.                     8.54e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.54e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'origin_Europe' column\n",
    "X1 = X.drop('origin_Europe', axis=1)\n",
    "\n",
    "# Refit the model and print the summary\n",
    "model1 = sm.OLS(y, X1).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.824\n",
      "Model:                            OLS   Adj. R-squared:                  0.821\n",
      "Method:                 Least Squares   F-statistic:                     300.1\n",
      "Date:                Wed, 03 Jan 2024   Prob (F-statistic):          8.89e-142\n",
      "Time:                        10:03:36   Log-Likelihood:                -1020.9\n",
      "No. Observations:                 392   AIC:                             2056.\n",
      "Df Residuals:                     385   BIC:                             2084.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const          -13.8400      4.113     -3.365      0.001     -21.927      -5.753\n",
      "displacement     0.0235      0.008      3.092      0.002       0.009       0.038\n",
      "cylinders       -0.4962      0.320     -1.551      0.122      -1.125       0.133\n",
      "horsepower      -0.0246      0.011     -2.294      0.022      -0.046      -0.004\n",
      "weight          -0.0065      0.001    -11.534      0.000      -0.008      -0.005\n",
      "model_year       0.7777      0.051     15.355      0.000       0.678       0.877\n",
      "origin_US       -2.7513      0.482     -5.710      0.000      -3.699      -1.804\n",
      "==============================================================================\n",
      "Omnibus:                       25.006   Durbin-Watson:                   1.285\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.852\n",
      "Skew:                           0.459   Prob(JB):                     6.03e-09\n",
      "Kurtosis:                       4.214   Cond. No.                     7.66e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.66e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'acceleration' column\n",
    "X2 = X1.drop('acceleration', axis=1)\n",
    "\n",
    "# Refit the model and print the summary\n",
    "model2 = sm.OLS(y, X2).fit()\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.823\n",
      "Model:                            OLS   Adj. R-squared:                  0.820\n",
      "Method:                 Least Squares   F-statistic:                     358.3\n",
      "Date:                Wed, 03 Jan 2024   Prob (F-statistic):          1.48e-142\n",
      "Time:                        10:11:05   Log-Likelihood:                -1022.1\n",
      "No. Observations:                 392   AIC:                             2056.\n",
      "Df Residuals:                     386   BIC:                             2080.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const          -15.0080      4.051     -3.705      0.000     -22.973      -7.043\n",
      "displacement     0.0157      0.006      2.747      0.006       0.004       0.027\n",
      "horsepower      -0.0227      0.011     -2.131      0.034      -0.044      -0.002\n",
      "weight          -0.0066      0.001    -11.750      0.000      -0.008      -0.005\n",
      "model_year       0.7779      0.051     15.331      0.000       0.678       0.878\n",
      "origin_US       -2.6889      0.481     -5.590      0.000      -3.635      -1.743\n",
      "==============================================================================\n",
      "Omnibus:                       24.003   Durbin-Watson:                   1.271\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.964\n",
      "Skew:                           0.447   Prob(JB):                     1.55e-08\n",
      "Kurtosis:                       4.184   Cond. No.                     7.53e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.53e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'cylinders' column\n",
    "X3 = X2.drop('cylinders', axis=1)\n",
    "\n",
    "# Refit the model and print the summary\n",
    "model3 = sm.OLS(y, X3).fit()\n",
    "print()\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE when using all features:         99.67098477764772\n",
      "MSE when using only useful features: 98.94744747911336\n"
     ]
    }
   ],
   "source": [
    "# Perform train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=334)\n",
    "y_test = y_test.values\n",
    "\n",
    "# Train the first model, and get the MSE on the test set\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "y_pred = model.predict(X_test).values\n",
    "mse = np.mean((y_pred - y_test)**2)\n",
    "print(f'MSE when using all features:         {mse}')\n",
    "\n",
    "# Now, remove the features we decided weren't useful through stepwise feature removal, and get the MSE on the test set\n",
    "X_train = X_train.drop(['origin_Europe', 'acceleration', 'cylinders'], axis=1)\n",
    "X_test = X_test.drop(['origin_Europe', 'acceleration', 'cylinders'], axis=1)\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "y_pred = model.predict(X_test).values\n",
    "mse = np.mean((y_pred - y_test)**2)\n",
    "print(f'MSE when using only useful features: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $L^1$ Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lars_model = LassoLarsIC(criterion='bic', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('const', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=334)\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoLarsIC(criterion='bic', normalize=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "lars_model.fit(X_train, y_train.values.reshape(1, -1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             BIC criterion\n",
      "alphas                    \n",
      "5791.332580    3181.170871\n",
      "23.835366      1837.591358\n",
      "15.655978      1838.232508\n",
      "8.145562       1831.269152\n",
      "2.384037       1674.376395\n",
      "0.663504       1660.903465\n",
      "0.295187       1665.666492\n",
      "0.232070       1662.522325\n",
      "0.188430       1663.228888\n",
      "0.033225       1655.087183\n",
      "0.000000       1659.478067\n"
     ]
    }
   ],
   "source": [
    "# Get the results from the model\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"alphas\": lars_model.alphas_,\n",
    "        \"BIC criterion\": lars_model.criterion_,\n",
    "    }\n",
    ").set_index(\"alphas\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02359115, -0.61367486, -0.01471611, -0.00695722,  0.04982891,\n",
       "        0.74492259,  0.        , -2.30763917])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get coefficients from the model\n",
    "lars_model.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE when alpha=0:         99.6709847776471\n",
      "MSE when alpha=0.033225:  98.75552193526808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lasso_no_alpha = LinearRegression().fit(X_train, y_train.values.reshape(1, -1)[0])\n",
    "\n",
    "# Get the MSE on the test set for each model\n",
    "y_pred_no_alpha = lasso_no_alpha.predict(X_test)\n",
    "y_pred_opt_alpha = lars_model.predict(X_test)\n",
    "\n",
    "mse_no_alpha = np.mean((y_pred_no_alpha - y_test)**2)\n",
    "mse_opt_alpha = np.mean((y_pred_opt_alpha - y_test)**2)\n",
    "\n",
    "print(f'MSE when alpha=0:         {mse_no_alpha}')\n",
    "print(f'MSE when alpha=0.033225:  {mse_opt_alpha}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acme1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
